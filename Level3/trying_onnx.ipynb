{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"  # or \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Sample input to the model\n",
    "seed_text = \" \"\n",
    "input_ids = tokenizer.encode(seed_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Define the output path for the ONNX model\n",
    "onnx_model_path = \"gpt2.onnx\"\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(\n",
    "    model,                                 # Model to export\n",
    "    input_ids,                             # Sample input\n",
    "    onnx_model_path,                       # Output file path\n",
    "    export_params=True,                    # Store the trained parameters\n",
    "    opset_version=11,                      # ONNX opset version\n",
    "    do_constant_folding=True,              # Optimization flag\n",
    "    input_names=[\"input_ids\"],             # Model's input name\n",
    "    output_names=[\"logits\"],               # Model's output name\n",
    "    dynamic_axes={\"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"}, # Dynamic axes\n",
    "                  \"logits\": {0: \"batch_size\", 1: \"sequence_length\"}},\n",
    ")\n",
    "\n",
    "print(f\"Model exported to {onnx_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
